{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cache the imput images\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import urllib\n",
    "\n",
    "# open the list of images\n",
    "f = open('input/data_340_images.csv', 'r')\n",
    "reader = csv.DictReader(f)\n",
    "\n",
    "# for each image in the dataset\n",
    "for row in reader:\n",
    "    \n",
    "    # get the url\n",
    "    url = row['url']\n",
    "    \n",
    "    # get the filename from the url\n",
    "    fname = url.split('/')[-1]\n",
    "\n",
    "    # download the file only if it is not yet cached locally\n",
    "    if os.path.isfile(\"img/\"+fname) <> True:\n",
    "        \n",
    "        # verify that the file is accesable\n",
    "        r = requests.head(url)\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            # download the image\n",
    "            img = urllib.urlopen(url)\n",
    "            \n",
    "            # save the image\n",
    "            with open(\"img/\"+fname, 'wb') as f:\n",
    "                f.write(img.read())\n",
    "        else:\n",
    "            print fname,'does not exist'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 340\n",
      "Batches: 12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Generate input document\n",
    "# Input documents are generated so that\n",
    "# 1) A crowd worker never sees the same image twice\n",
    "# 2) The order of the durations is unpredictable\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# the durations to show the images for\n",
    "durations = [1,5,15,20]\n",
    "durationCount = len(durations)\n",
    "\n",
    "# amount of images in one batch\n",
    "batchSize = 30\n",
    "# current batch size do handle final batch with smaller size\n",
    "thisBatchSize = batchSize\n",
    "\n",
    "break # do not execute\n",
    "\n",
    "# open the list of images\n",
    "f = open('input/data_340_images.csv', 'r')\n",
    "reader = csv.DictReader(f)\n",
    "\n",
    "# make a list of the input images\n",
    "images = list(reader)\n",
    "\n",
    "# get a random order of the images - excluding first batch\n",
    "images = list(images[0:batchSize])+random.sample(images[batchSize:], len(images[batchSize:]))\n",
    "\n",
    "imageCount = len(images)\n",
    "print 'Images:',imageCount\n",
    "\n",
    "# number of batches\n",
    "batchCount = int(math.ceil(float(imageCount)/batchSize))\n",
    "print 'Batches:',batchCount\n",
    "\n",
    "# for each batch generate the input file\n",
    "id = 0\n",
    "batchStart = 0\n",
    "for b in range(batchCount):\n",
    "    \n",
    "    fieldnames = ['row','batch','image','sequence','duration','url']\n",
    "    w = open('input/batch_'+str(b)+'.csv', 'wb')\n",
    "    wr = csv.writer(w, delimiter=',')\n",
    "    wr.writerow(fieldnames)\n",
    "    \n",
    "    # if this is the last batch change the batch size\n",
    "    if b == batchCount -1:\n",
    "        thisBatchSize = imageCount % batchSize\n",
    "    \n",
    "    # generate a random sequence for this batch\n",
    "    sequence = []\n",
    "    for x in range(thisBatchSize):\n",
    "        sequence.append(random.choice(range(len(durations))))\n",
    "    \n",
    "    \n",
    "    for d in range(durationCount):\n",
    "        for i in range(thisBatchSize):\n",
    "            \n",
    "            # compute the image number\n",
    "            image = b*batchSize+i\n",
    "            url = images[image]['url']\n",
    "            fname = url.split('/')[-1]\n",
    "            \n",
    "            # write row to file\n",
    "            wr.writerow([id,b,fname,i,durations[sequence[i]],url])\n",
    "            \n",
    "            # update the sequence for the next duration\n",
    "            if sequence[i] >= durationCount-1:\n",
    "                sequence[i] = 0\n",
    "            else:\n",
    "                sequence[i] = sequence[i]+1\n",
    "                        \n",
    "            # increment number over all appearances\n",
    "            id = id+1\n",
    "    print b\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_0-f952513.csv\n",
      "batch_1-f954112.csv\n",
      "batch_10-f961822.csv\n",
      "batch_11-f962750.csv\n",
      "batch_2-f954265.csv\n",
      "batch_3-f954602.csv\n",
      "batch_4-f954944.csv\n",
      "batch_5-f955387.csv\n",
      "batch_6-f956267.csv\n",
      "batch_7-f958354.csv\n",
      "batch_8-f959516.csv\n",
      "batch_9-f960620.csv\n",
      "pilot_1-f912713.csv\n",
      "pilot_2-f920336.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Load the crowdsourcing results:\n",
    "\n",
    "# Import lxml:\n",
    "from lxml import etree as et\n",
    "import scipy.spatial\n",
    "from random import randint\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import unicodecsv\n",
    "\n",
    "\n",
    "# load crowdsourcing results\n",
    "wd = '/Users/benjamin/Google Drive/Crowd-WATSON/Research/Visual Metaphors (Benjamin, Marianna)/3-raw-results/'\n",
    "\n",
    "# images --> durations --> workers\n",
    "images = {}\n",
    "\n",
    "jobs = os.listdir(wd)\n",
    "for job in jobs:\n",
    "    if not ((job.startswith('pilot') or job.startswith('batch')) and job.endswith('.csv')):\n",
    "        continue\n",
    "\n",
    "    print job\n",
    "    \n",
    "\n",
    "    f = open(wd+job, 'r')\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "\n",
    "\n",
    "\n",
    "        # get key values\n",
    "        url = row['url']\n",
    "        i = url.split('/')[-1]\n",
    "        d = int(row['duration'])\n",
    "        hit = row['_id']\n",
    "        w = row['_worker_id']\n",
    "\n",
    "        # add image if it is not in the dictionary\n",
    "        if i not in images:\n",
    "            images[i] = {\n",
    "                'durations':{},\n",
    "                'url': row['url'], \n",
    "                'job': job\n",
    "            }\n",
    "\n",
    "        if d not in images[i]['durations']:\n",
    "            images[i]['durations'][d] = {'workers':{},}\n",
    "\n",
    "        if w not in images[i]['durations'][d]:\n",
    "            images[i]['durations'][d]['workers'][w] = {\n",
    "                'tags' : {t:1 for t in set(row['tags'].split(','))},\n",
    "                'feedback' : row['feedback'],\n",
    "                'before' : float(row['time_before']),\n",
    "                'during' : float(row['time_during']),\n",
    "                'after' : float(row['time_after']),\n",
    "                'time' : float(row['time_total']),\n",
    "                'started' : row['_started_at'],\n",
    "                'ended' : row['_created_at'],\n",
    "                'channel' : row['_channel'],\n",
    "                'country' : row['_country'],\n",
    "                'region' : row['_region'],\n",
    "                'city' : row['_city'],\n",
    "                'ip' : row['_ip'],\n",
    "                'browser' : row['browser'],\n",
    "                'window_height' : row['browser_height'],\n",
    "                'window_width' : row['browser_width']\n",
    "            }    \n",
    "        else:\n",
    "            print 'duplicate',worker\n",
    "\n",
    "    f.close()\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Distributions of singletons and doubles per duration\n",
    "A matrix of all images x all the tags (people)\n",
    "A matrix of all images x all tags (machine)\n",
    "Compare the visual tags with tags\n",
    "Concreteness ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94265 tags using  16397  unique tags after original\n",
      "94265 tags using  16397  unique tags after clean_spaces\n",
      "94253 tags using  16395  unique tags after clean_empty\n",
      "94253 tags using  16395  unique tags after clean_lowercase\n",
      "94253 tags using  16395  unique tags after clean_hashtag\n",
      "94253 tags using  16395  unique tags after clean_minus\n",
      "94253 tags using  16395  unique tags after clean_empty\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clean the tags\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#cleaning functions\n",
    "def original(tag):\n",
    "    return tag\n",
    "\n",
    "def clean_spaces(tag):\n",
    "    tag = tag.strip()\n",
    "    return tag\n",
    "\n",
    "def clean_empty(tag):\n",
    "    if tag == \"\":\n",
    "        return False\n",
    "    else:\n",
    "        return tag\n",
    "\n",
    "def clean_lowercase(tag):\n",
    "    tag = tag.lower()\n",
    "    return tag\n",
    "\n",
    "def clean_hashtag(tag):\n",
    "    tag = tag.replace(\"#\",\"\")\n",
    "    return tag\n",
    "\n",
    "def clean_minus(tag):\n",
    "    tag = tag.replace(\"-\",\"\")\n",
    "    return tag\n",
    "\n",
    "def clean_stopwords(tag):\n",
    "    words = [i for i in tag.split() if i not in stop]\n",
    "    if len(words) > 0 and len([w for w in words]) > 0:\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        print tag\n",
    "        return False\n",
    "    \n",
    "# functions to clean the tags on:\n",
    "clean_functions = [original,\n",
    "                   clean_spaces,\n",
    "                   clean_empty,\n",
    "                   clean_lowercase,\n",
    "                   clean_hashtag,\n",
    "                   clean_minus,\n",
    "                   clean_empty]\n",
    "                   #clean_stopwords]\n",
    "\n",
    "# clean with each function\n",
    "for c in tnrange(len(clean_functions), desc='Progress'):\n",
    "    cleaner = clean_functions[c]\n",
    "    imagekeys = images.keys()\n",
    "    # record performance\n",
    "    log = {'tags':[],'judgments':[]}\n",
    "\n",
    "    for ti in tnrange(len(images), desc=cleaner.__name__):\n",
    "        i = imagekeys[ti]\n",
    "        vector = {}\n",
    "        \n",
    "        for d in images[i]['durations']:\n",
    "            \n",
    "            for w in images[i]['durations'][d]['workers']:\n",
    "            \n",
    "                tags_to_clean = images[i]['durations'][d]['workers'][w]['tags']\n",
    "                images[i]['durations'][d]['workers'][w]['tags'] = {}\n",
    "                \n",
    "                for tag in tags_to_clean:\n",
    "                    # run cleaning function on tag\n",
    "                    cleaned_tag = cleaner(tag)\n",
    "\n",
    "                    if cleaned_tag is not False:\n",
    "                        images[i]['durations'][d]['workers'][w]['tags'][cleaned_tag] = 1\n",
    "                        log['tags'].append(tag)\n",
    "    \n",
    "    print len(log['tags']),'tags using ',len(set(log['tags'])),' unique tags after',cleaner.__name__  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build cache of POS tag and sentiment\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import csv\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "\n",
    "def treebank_to_wordnet_pos(treebank, skipWordNetPos=[]):\n",
    "    if \"NN\" in treebank and \"n\" not in skipWordNetPos: # singular and plural nouns (NN, NNS)\n",
    "        return \"n\"\n",
    "    elif \"JJ\" in treebank and \"a\" not in skipWordNetPos: # adjectives including comparatives and superlatives (JJ, JJR, JJS)\n",
    "        return \"a\" \n",
    "    elif \"VB\" in treebank and \"v\" not in skipWordNetPos: # verbs in various forms (VB, VBD, VBG, VBN, VBP, VBZ)\n",
    "        return \"v\"\n",
    "    elif \"RB\" in treebank and \"r\" not in skipWordNetPos: # adverbs including comparatives and superlatives (RB, RBR, RBS)\n",
    "        return \"r\"\n",
    "\n",
    "def get_sentiment_score_from_tagged(token, treebank, skipWordNetPos=[]):\n",
    "    wordnet_pos = treebank_to_wordnet_pos(treebank, skipWordNetPos)\n",
    "    if wordnet_pos:\n",
    "        senti_synsets = list(swn.senti_synsets(token, wordnet_pos))\n",
    "        if senti_synsets:\n",
    "            return wordnet_pos,senti_synsets[0].pos_score(),senti_synsets[0].neg_score(),senti_synsets[0].obj_score()\n",
    "        else:\n",
    "            return wordnet_pos,0,0,0\n",
    "    else:\n",
    "        return '?',0,0,0\n",
    "\n",
    "\n",
    "types = {}\n",
    "keys = set([tag for i in images for d in images[i]['durations'] for w in images[i]['durations'][d]['workers'] for tag in images[i]['durations'][d]['workers'][w]['tags'].keys()])\n",
    "\n",
    "for key in keys:\n",
    "    \n",
    "    tokens=nltk.word_tokenize(key.decode('utf-8'))\n",
    "    tagged=nltk.pos_tag(tokens)\n",
    "    types[key] = {\n",
    "        'words' : 0,\n",
    "        'pos' : {\n",
    "            'n' : 0,\n",
    "            'a' : 0,\n",
    "            'v' : 0,\n",
    "            'r' : 0,\n",
    "            '?' : 0\n",
    "        },\n",
    "        'sentiment' : {\n",
    "            'p' : 0,\n",
    "            'n' : 0,\n",
    "            'o' : 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for word, treebank in tagged:\n",
    "        tag,pos,neg,obj = get_sentiment_score_from_tagged(word, treebank, skipWordNetPos=[])\n",
    "        types[key]['words'] += 1\n",
    "        types[key]['pos'][tag] += 1\n",
    "        types[key]['sentiment']['p'] += pos\n",
    "        types[key]['sentiment']['n'] += neg\n",
    "        types[key]['sentiment']['o'] += obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(wd+'machine-tag-cache.csv', 'r')\n",
    "reader = csv.DictReader(f)\n",
    "\n",
    "machine_tags = {}\n",
    "\n",
    "for frow in reader:\n",
    "    \n",
    "    i = frow['url'].split('/')[-1]\n",
    "    machine_tags[i] = {\n",
    "        'imagga' : json.loads(frow['imagga']),\n",
    "        'clarifai' : json.loads(frow['clarifai'])\n",
    "    }\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute cosine distances - this may take a while\n",
    "scores = {}\n",
    "keys = images.keys()\n",
    "for im in tnrange(len(images), desc='Scores'):\n",
    "    i = keys[im]\n",
    "    scores[i] = {'clarity':0, 'vector':{}}\n",
    "    scores[i]['vector'] = get_sentence_relation_score(stats['images'][i]['tags'])\n",
    "    scores[i]['clarity'] = get_sentence_clarity(scores[i]['vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate results\n",
    "def get_sentence_relation_score(annotation_vector):\n",
    "    #OUTPUT: sentence_relation_scores = {sentence : {relation : score}}\n",
    "    sentence_relation_scores = {}\n",
    "    for relation in annotation_vector:\n",
    "        relation_scores = {}\n",
    "        total_annotations = [annotation_vector[rel] for rel in annotation_vector]\n",
    "        relations = [rel for rel in annotation_vector]\n",
    "        for i in range(0, len(total_annotations)):\n",
    "            unit_vector = [0 for j in range(0, len(total_annotations))]\n",
    "            unit_vector[i] = 1\n",
    "            sentence_relation_score = 1.0-scipy.spatial.distance.cosine(unit_vector,total_annotations)\n",
    "            relation_scores[relations[i]] = round(sentence_relation_score,3)\n",
    "    return relation_scores\n",
    "\n",
    "def get_sentence_clarity(relation_scores):\n",
    "    #OUTPUT: sentence_clarity = {sentence : score}\n",
    "    scores = []\n",
    "    for relation in relation_scores:\n",
    "        scores.append(relation_scores[relation])\n",
    "    clarity = round(max(scores),3)\n",
    "    return clarity\n",
    "\n",
    "\n",
    "stats = {\n",
    "    'jobs' : {},\n",
    "    'images' : {},\n",
    "    'durations' : {},\n",
    "    'workers' : {},\n",
    "    'tags' : {}\n",
    "    }\n",
    "total = {'jobs':{},'images':{},'durations':{1:[],5:[],15:[],20:[]},'judgments':0,'workers':{},'tags':{}}\n",
    "\n",
    "# new entity\n",
    "def new(haystack, needle):\n",
    "    if needle not in haystack:\n",
    "        haystack[needle] = {'jobs':{},'images':{},'judgments':0,'durations':{1:[],5:[],15:[],20:[]},'workers':{},'tags':{}}\n",
    "    return haystack\n",
    "\n",
    "# add needle to haystack or increment existing\n",
    "def inc(haystack, needle):\n",
    "    if needle not in haystack:\n",
    "        haystack[needle] = 0\n",
    "    haystack[needle] += 1\n",
    "    return haystack\n",
    "\n",
    "\n",
    "# each image\n",
    "keys = images.keys()\n",
    "for im in tnrange(len(images), desc='Aggregating'):\n",
    "    i = keys[im]\n",
    "    j = images[i]['job']\n",
    "    \n",
    "    inc(total['jobs'], j)\n",
    "    inc(total['images'], i)\n",
    "    \n",
    "    new(stats['jobs'], j)\n",
    "    inc(stats['jobs'][j]['jobs'], j)\n",
    "    inc(stats['jobs'][j]['images'], i)\n",
    "    \n",
    "    new(stats['images'], i)\n",
    "    inc(stats['images'][i]['jobs'], j)\n",
    "    inc(stats['images'][i]['images'], i)\n",
    "    \n",
    "    # each duration\n",
    "    for d in images[i]['durations']:\n",
    "        new(stats['durations'], d)\n",
    "        inc(stats['durations'][d]['jobs'], j)\n",
    "        inc(stats['durations'][d]['images'], i)\n",
    "        \n",
    "        # each worker\n",
    "        for w in images[i]['durations'][d]['workers']:\n",
    "            new(stats['workers'], w)\n",
    "            inc(stats['workers'][w]['jobs'], j)\n",
    "            inc(stats['workers'][w]['images'], i)\n",
    "            \n",
    "            inc(total['workers'], w)\n",
    "            inc(stats['jobs'][j]['workers'], w)\n",
    "            inc(stats['durations'][d]['workers'], w)            \n",
    "            inc(stats['images'][i]['workers'], w)\n",
    "            \n",
    "            # each tag\n",
    "            for t in images[i]['durations'][d]['workers'][w]['tags']:\n",
    "                new(stats['tags'], t)\n",
    "                inc(stats['tags'][t]['jobs'], j)\n",
    "                \n",
    "                inc(stats['tags'][t]['images'], i)\n",
    "                inc(stats['tags'][t]['workers'], w)\n",
    "                stats['tags'][t]['durations'][d].append(1)\n",
    "                stats['tags'][t]['judgments'] += 1\n",
    "                \n",
    "                inc(total['tags'], t)\n",
    "                inc(stats['jobs'][j]['tags'], t)\n",
    "                inc(stats['images'][i]['tags'], t)\n",
    "                inc(stats['durations'][d]['tags'], t)\n",
    "                inc(stats['workers'][w]['tags'], t)\n",
    "                inc(stats['tags'][t]['tags'], t)\n",
    "                \n",
    "            \n",
    "            # judgments\n",
    "            total['judgments'] += 1\n",
    "            stats['jobs'][j]['judgments'] += 1\n",
    "            stats['images'][i]['judgments'] += 1\n",
    "            stats['durations'][d]['judgments'] += 1\n",
    "            stats['workers'][w]['judgments'] += 1\n",
    "            \n",
    "            # durations\n",
    "            total['durations'][d].append(len(images[i]['durations'][d]['workers'][w]['tags']))\n",
    "            stats['jobs'][j]['durations'][d].append(len(images[i]['durations'][d]['workers'][w]['tags']))\n",
    "            stats['images'][i]['durations'][d].append(len(images[i]['durations'][d]['workers'][w]['tags']))\n",
    "            stats['workers'][w]['durations'][d].append(len(images[i]['durations'][d]['workers'][w]['tags']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\n",
      "durations\n",
      "jobs\n",
      "workers\n",
      "tags\n"
     ]
    }
   ],
   "source": [
    "# get metrics over total set\n",
    "totalMetrics = getMetrics(0, 'total', total)\n",
    "\n",
    "def getMetrics(s, x, stat):\n",
    "    jobCount = len(stat['jobs'])\n",
    "    if jobCount == 1:\n",
    "        jobCount = ''.join(stat['jobs'])\n",
    "    imageCount = len(stat['images'])\n",
    "    workerCount = len(stat['workers'])\n",
    "    judgmentCount = stat['judgments']\n",
    "    tags = stat['tags']\n",
    "    tagCount = float(sum(tags.values()))\n",
    "    uniqueTags = len(tags)\n",
    "    uniquePerImage = uniqueTags / float(imageCount)\n",
    "    tagsPerImage = tagCount / float(imageCount)\n",
    "    tagsPerJudgment = tagCount / float(judgmentCount)\n",
    "    singletons = len([t for t in tags if tags[t] == 1])\n",
    "    doubles = len([t for t in tags if tags[t] == 2])\n",
    "    \n",
    "    clarity = 0\n",
    "    # CrowdTruth clarity\n",
    "    if s == 'images':\n",
    "        clarity = scores[i]['clarity']\n",
    "\n",
    "    # pos tags\n",
    "    words = float(sum(types[tag]['words']*tags[tag] for tag in tags))\n",
    "    wordsPerTag = words / tagCount\n",
    "    if words == 0:\n",
    "        print tags\n",
    "    nouns = sum(types[tag]['pos']['n']*tags[tag] for tag in tags) / words\n",
    "    adjectives = sum(types[tag]['pos']['a']*tags[tag] for tag in tags) / words\n",
    "    verbs = sum(types[tag]['pos']['v']*tags[tag] for tag in tags) / words\n",
    "    adverbs = sum(types[tag]['pos']['r']*tags[tag] for tag in tags) / words\n",
    "    other = sum(types[tag]['pos']['?']*tags[tag] for tag in tags) / words\n",
    "    \n",
    "    # sentiment\n",
    "    pos = sum(types[tag]['sentiment']['p']*tags[tag] for tag in tags) / words\n",
    "    neg = sum(types[tag]['sentiment']['n']*tags[tag] for tag in tags) / words\n",
    "    obj = sum(types[tag]['sentiment']['o']*tags[tag] for tag in tags) / words\n",
    "    \n",
    "    # list of tags\n",
    "    tagList = ', '.join([t[0]+':'+str(t[1]) for t in sorted(tags.items(), key=lambda x: x[1], reverse=True)])\n",
    "    if x == 'total' or s == 'durations':\n",
    "        tagList = ''\n",
    "    return [\n",
    "        x, \n",
    "        jobCount, \n",
    "        imageCount, \n",
    "        workerCount, \n",
    "        judgmentCount, \n",
    "        len(stat['durations'][1]), \n",
    "        len(stat['durations'][5]), \n",
    "        len(stat['durations'][15]), \n",
    "        len(stat['durations'][20]), \n",
    "        tagCount,\n",
    "        sum(stat['durations'][1]), \n",
    "        sum(stat['durations'][5]), \n",
    "        sum(stat['durations'][15]), \n",
    "        sum(stat['durations'][20]), \n",
    "        uniqueTags, \n",
    "        uniquePerImage,\n",
    "        tagsPerImage,\n",
    "        tagsPerJudgment, \n",
    "        singletons, \n",
    "        doubles,\n",
    "        words,\n",
    "        wordsPerTag,\n",
    "        nouns, \n",
    "        adjectives, \n",
    "        verbs, \n",
    "        adverbs, \n",
    "        pos, \n",
    "        neg, \n",
    "        obj, \n",
    "        clarity,\n",
    "        tagList]\n",
    "\n",
    "for s in stats:\n",
    "    print s\n",
    "    \n",
    "    # save to file\n",
    "    wf = open(wd+'../4-analysis/all-'+s+'.csv', 'wb')\n",
    "    wr = csv.writer(wf, delimiter=',')\n",
    "    fieldnames = [s, 'jobs','images','workers','judgments','judgments-1s','judgments-5s','judgments-15s','judgments-20s','tags','tags-1s','tags-5s','tags-15s','tags-20s','uniqueTags','uniquePerImage','tagsPerImage','tagsPerJudgment','singletons','doubles','words','wordsPerTag','nouns','adjectives','verbs','adverbs','other','positivity','negativity','objectivity','clarity','tags']\n",
    "    wr.writerow(fieldnames)\n",
    "\n",
    "    # each row in this stat type\n",
    "    for x in stats[s]:\n",
    "        row = getMetrics(s, x, stats[s][x])\n",
    "        wr.writerow(row)\n",
    "    wr.writerow(totalMetrics)\n",
    "    wf.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'workers', 'cos_clarity', 'man', 'people', 'men', 'cartoon', 'water', 'hand', 'money', 'hands', 'gun', 'person', 'woman', 'drawing', 'brain', 'red', 'tree', 'sky', 'blue', 'book', 'stars', 'car', 'head', 'black', 'flag', 'boat', 'obama', 'clouds', 'art', 'hat', 'face', 'ocean', 'scissors', 'city', 'ship', 'clock', 'white', 'bird', 'flower', 'blood', 'trees', 'suit', 'death', 'knife', 'sea', 'moon', 'computer', 'rope', 'fork', 'green', 'horse', 'coffee', 'glasses', 'buildings', 'eu', 'fish', 'earth', 'apple', 'walking', 'bottle', 'audi', 'cage', 'europe', 'tv', 'beach', 'flowers', 'spoon', 'arrow', 'map', 'paper', 'building', 'beer', 'plant', 'eye', 'glass', 'birds', 'food', 'mouse', 'painting', 'bread', 'grass', 'child', 'table', 'world', 'flags', 'window', 'time', 'graph', 'newspaper', 'america', 'leaves', 'finger', 'bullet', 'sword', 'atm', 'door', 'castle', 'war', 'wall', 'stairs', 'fire', 'eggs']\n"
     ]
    }
   ],
   "source": [
    "# save matrix with top 100 tags vs all images\n",
    "top = [x[0] for x in sorted(stats['tags'].items(), key=lambda x: x[1]['judgments'], reverse=True)[:100]]\n",
    "\n",
    "wf = open(wd+'../4-analysis/tag-matrix.csv', 'wb')\n",
    "wr = csv.writer(wf, delimiter=',')\n",
    "fieldnames = ['image','workers','cos_clarity']+top\n",
    "print fieldnames\n",
    "wr.writerow(fieldnames)\n",
    "\n",
    "for i in images:\n",
    "    # each duration\n",
    "    row = ['http://www.vismet.org/VisMet/images/thumbs/'+i]\n",
    "    row.append(len(stats['images'][i]['workers']))\n",
    "    row.append(scores[i]['clarity'])\n",
    "    for t in top:\n",
    "        if t in scores[i]['vector']:\n",
    "            row.append(scores[i]['vector'][t])\n",
    "        else:\n",
    "            row.append(0)\n",
    "    wr.writerow(row)\n",
    "wf.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# print venn diagram with term overlap between durations\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "\n",
    "overlap = {}\n",
    "for x in stats['durations']:\n",
    "    overlap[x] = set(stats['durations'][x]['tags'].keys())\n",
    "\n",
    "for key in sorted(list(overlap[15])):\n",
    "    print key\n",
    "    \n",
    "break\n",
    "for x in [1,5,15,20]:\n",
    "    for y in [1,5,15,20]:\n",
    "        intersect = overlap[x].intersection(overlap[y])\n",
    "        print x,y,len(intersect),len(overlap[x]-overlap[y])\n",
    "        #print x,y,float(len(overlap[x]&overlap[y])) * 100\n",
    "    \n",
    "    \n",
    "venn3([overlap[20],overlap[5],overlap[15]], ('1s', '5s', '15s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    " \n",
    "    - number of tags\n",
    "    - number of unique tags\n",
    "    - workers\n",
    "    - avg tags per image\n",
    "    - avg tags per worker\n",
    "    - singletons\n",
    "    - doubles\n",
    "    - lexical types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "fieldnames = ['image_id','tag','original','crowd_1s','crowd_5s','crowd_15s','crowd_20s','crowd_judgments','crowd_relation_score','crowd_image_clarity','imagga','clarifai','pos_tags','pos_class','sentiment_positive','sentiment_negative','sentiment_objectivity','url']\n",
    "durations = [1,5,15,20]\n",
    "    \n",
    "\n",
    "\n",
    "wi = open(wd+'../4-analysis/per-image.csv', 'wb')\n",
    "wri = csv.writer(wi, delimiter=',')\n",
    "#wri.writerow(fieldnames)\n",
    "\n",
    "irow = {}\n",
    "\n",
    "for i in images:\n",
    "\n",
    "    vector = {key:0 for d in images[i]['durations'] for w in images[i]['durations'][d]['workers'] for key in images[i]['durations'][d]['workers'][w]['tags'].keys()}\n",
    "\n",
    "    if i in machine_tags:\n",
    "        keys = list(set(vector.keys()+machine_tags[i]['imagga'].keys()+machine_tags[i]['clarifai'].keys()))\n",
    "    else:\n",
    "        keys = list(set(vector.keys()))\n",
    "    \n",
    "    keys.sort()\n",
    "    break\n",
    "\n",
    "    for k in tnrange(len(keys), desc='Progress'):\n",
    "        key = keys[k]\n",
    "        \n",
    "        row = [image,key]\n",
    "\n",
    "        # if tag was replaced\n",
    "        if key in stats['replaced'][image]:\n",
    "            string = ','.join(set(stats['replaced'][image][key]))\n",
    "            row.extend([string])\n",
    "        else:\n",
    "            row.extend([''])\n",
    "        judgments = 0\n",
    "        for dur in durations:\n",
    "            if dur in images[image]:\n",
    "                if key in images[image][dur]['tags']:\n",
    "                    row.extend([images[image][dur]['tags'][key]])\n",
    "                    judgments += images[image][dur]['tags'][key]\n",
    "                else:\n",
    "                    row.extend([0])\n",
    "            else:\n",
    "                row.extend([0])\n",
    "            \n",
    "\n",
    "        row.extend([judgments])\n",
    "        if key in stats['rel_scores'][image]:\n",
    "            row.extend([stats['rel_scores'][image][key]])\n",
    "        else:\n",
    "            row.extend([0])\n",
    "        row.extend([stats['clarity'][image]])\n",
    "            \n",
    "\n",
    "        if key not in imagga:\n",
    "            row.extend([0])\n",
    "        else:\n",
    "            row.extend([imagga[key]])\n",
    "    \n",
    "        if key not in clarifai:\n",
    "            row.extend([0])\n",
    "            \n",
    "        else:\n",
    "            row.extend([clarifai[key]])\n",
    "            \n",
    "            \n",
    "\n",
    "        tokens=nltk.word_tokenize(key) #for tokenization, row is line of a file in which tweets are saved.\n",
    "        tagged=nltk.pos_tag(tokens) #for POSTagging\n",
    "        pscore = 0\n",
    "        nscore = 0\n",
    "        oscore = 0\n",
    "        \n",
    "        for word, treebank in tagged:\n",
    "            tag,pos,neg,obj = get_sentiment_score_from_tagged(word, treebank, skipWordNetPos=[])\n",
    "            pscore = pscore + pos\n",
    "            nscore = nscore + neg\n",
    "            oscore = oscore + obj\n",
    "\n",
    "            \n",
    "        row.extend([tagged,tag])\n",
    "        \n",
    "        row.extend([pscore,nscore,oscore])\n",
    "        \n",
    "        row.extend([imageurls[image]])\n",
    "\n",
    "        wr.writerow(row)\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = range(0,len(clean_functions))\n",
    "plt.plot(x,log['tags'])\n",
    "plt.plot(x,log['judgments'])\n",
    "plt.plot(x,log['clarity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize tags\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "for image in images:\n",
    "\n",
    "    im = mpimg.imread(\"img/\"+image+\".jpg\")\n",
    "    \n",
    "    figure(figsize = (10,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "   \n",
    "    keys = [key for dur in images[image] for key in images[image][dur]['tags'].keys()]\n",
    "\n",
    "    print \"Total keywords:\",len(keys)\n",
    "    keys = sort(list(set(keys)))\n",
    "    print \"Unique keywords:\",len(keys)\n",
    "    \n",
    "    N = len(keys)\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.20       # the width of the bars\n",
    "   \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    yvals = []\n",
    "    for key in keys:\n",
    "        if key not in images[image][1]['tags']:\n",
    "            yvals.append(0)\n",
    "        else:\n",
    "            yvals.append(images[image][1]['tags'][key])\n",
    "    rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "    zvals = []\n",
    "    for key in keys:\n",
    "        if key not in images[image][5]['tags']:\n",
    "            zvals.append(0)\n",
    "        else:\n",
    "            zvals.append(images[image][5]['tags'][key])\n",
    "    rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "    kvals = []\n",
    "    for key in keys:\n",
    "        if key not in images[image][15]['tags']:\n",
    "            kvals.append(0)\n",
    "        else:\n",
    "            kvals.append(images[image][15]['tags'][key])\n",
    "    rects3 = ax.bar(ind+width*2, kvals, width, color='b')\n",
    "    \n",
    "    ivals = []\n",
    "    for key in keys:\n",
    "        if key not in images[image][20]['tags']:\n",
    "            ivals.append(0)\n",
    "        else:\n",
    "            ivals.append(images[image][20]['tags'][key])\n",
    "    rects4 = ax.bar(ind+width*3, ivals, width, color='y')\n",
    "\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_xticks(ind+width)\n",
    "    ax.set_xticklabels( (keys) )\n",
    "    ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('1s', '5s', '15s', '20s') )\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            h = rect.get_height()\n",
    "            ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.setp(plt.xticks()[1], rotation=90)\n",
    "    plt.ylim(0,10)\n",
    "    fig.set_size_inches(15,3)\n",
    "    plt.savefig('results/'+filename+'/tags_image_'+image+'.png',bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "sort(stats['workers'])\n",
    "\n",
    "N = len(stats['workers'])\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.27       # the width of the bars\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "yvals = []\n",
    "for worker in stats['workers']:\n",
    "    if 1 not in stats['workers'][worker]:\n",
    "        yvals.append(0)\n",
    "    else:\n",
    "        yvals.append(len(stats['workers'][worker][1]))\n",
    "rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "\n",
    "zvals = []\n",
    "for worker in stats['workers']:\n",
    "    if 5 not in stats['workers'][worker]:\n",
    "        zvals.append(0)\n",
    "    else:\n",
    "        zvals.append(len(stats['workers'][worker][5]))\n",
    "rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "\n",
    "kvals = []\n",
    "for worker in stats['workers']:\n",
    "    if 15 not in stats['workers'][worker]:\n",
    "        kvals.append(0)\n",
    "    else:\n",
    "        kvals.append(len(stats['workers'][worker][15]))\n",
    "rects3 = ax.bar(ind+width*2, kvals, width, color='b')\n",
    "\n",
    "ivals = []\n",
    "for worker in stats['workers']:\n",
    "    if 20 not in stats['workers'][worker]:\n",
    "        ivals.append(0)\n",
    "    else:\n",
    "        ivals.append(len(stats['workers'][worker][20]))\n",
    "rects4 = ax.bar(ind+width*3, ivals, width, color='y')\n",
    "\n",
    "ax.set_ylabel('judgments')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( (stats['workers'].keys()) )\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('1s', '5s', '15s', '20s') )\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        h = rect.get_height()\n",
    "        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "plt.setp(plt.xticks()[1], rotation=90)\n",
    "fig.set_size_inches(15,3)\n",
    "plt.title('Judgments per worker for each image duration')\n",
    "plt.savefig('results/'+filename+'/worker_judgments.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np  \n",
    "\n",
    "N = len(stats['images'])\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.20       # the width of the bars\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "yvals = []\n",
    "for image in stats['images']:\n",
    "    if 1 not in stats['images'][image]:\n",
    "        yvals.append(0)\n",
    "    else:\n",
    "        yvals.append(stats['images'][image][1])\n",
    "rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "\n",
    "zvals = []\n",
    "for image in stats['images']:\n",
    "    if 5 not in stats['images'][image]:\n",
    "        zvals.append(0)\n",
    "    else:\n",
    "        zvals.append(stats['images'][image][5])\n",
    "rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "\n",
    "kvals = []\n",
    "for image in stats['images']:\n",
    "    if 15 not in stats['images'][image]:\n",
    "        kvals.append(0)\n",
    "    else:\n",
    "        kvals.append(stats['images'][image][15])\n",
    "rects3 = ax.bar(ind+width*2, kvals, width, color='b')\n",
    "\n",
    "ivals = []\n",
    "for image in stats['images']:\n",
    "    if 20 not in stats['images'][image]:\n",
    "        ivals.append(0)\n",
    "    else:\n",
    "        ivals.append(stats['images'][image][20])\n",
    "rects4 = ax.bar(ind+width*3, ivals, width, color='y')\n",
    "\n",
    "ax.set_ylabel('judgments')\n",
    "ax.set_xticks(ind+width*2)\n",
    "ax.set_xticklabels( (stats['images'].keys()) )\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('1s', '5s', '15s', '20s') )\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        h = rect.get_height()\n",
    "        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "plt.setp(plt.xticks()[1], rotation=90)\n",
    "fig.set_size_inches(15,3)\n",
    "plt.title('Judgments per image')\n",
    "plt.savefig('results/'+filename+'/image_judgments.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "print 'workers:',len(stats['workers'])\n",
    "\n",
    "N = len(stats['workers'])\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.27       # the width of the bars\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "yvals = []\n",
    "for worker in stats['workers']:\n",
    "    if 1 not in stats['workers'][worker]:\n",
    "        yvals.append(0)\n",
    "    else:\n",
    "        yvals.append(float(sum(stats['workers'][worker][1]))/len(stats['workers'][worker][1]))\n",
    "rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "\n",
    "zvals = []\n",
    "for worker in stats['workers']:\n",
    "    if 5 not in stats['workers'][worker]:\n",
    "        zvals.append(0)\n",
    "    else:\n",
    "        zvals.append(float(sum(stats['workers'][worker][5]))/len(stats['workers'][worker][5]))\n",
    "rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "\n",
    "kvals = []\n",
    "for worker in stats['workers']:\n",
    "    if 15 not in stats['workers'][worker]:\n",
    "        kvals.append(0)\n",
    "    else:\n",
    "        kvals.append(float(sum(stats['workers'][worker][15]))/len(stats['workers'][worker][15]))\n",
    "rects3 = ax.bar(ind+width*2, kvals, width, color='b')\n",
    "\n",
    "ax.set_ylabel('tags')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( (stats['workers'].keys()) )\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0]), ('1s', '5s', '15s') )\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        h = rect.get_height()\n",
    "        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "plt.setp(plt.xticks()[1], rotation=90)\n",
    "fig.set_size_inches(15,3)\n",
    "plt.title('Avg tags per worker for each image duration')\n",
    "plt.savefig('results/'+filename+'/worker_tags.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGJCAYAAAC3h1iaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9dec1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.855\n",
      "20 4.31\n",
      "5 3.62\n",
      "15 3.69\n",
      "avg: 4.21714285714\n"
     ]
    }
   ],
   "source": [
    "# Distribution of tags per judgment\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "sort(stats['tags'])\n",
    "bp = ax.boxplot([stats['tags'][dur] for dur in stats['tags']])\n",
    "ax.set_xticklabels( ([dur for dur in stats['tags']]) )\n",
    "plt.title(\"Number of tags in one judgment\")\n",
    "plt.xlabel(\"Image duration (seconds)\")\n",
    "plt.ylabel(\"Tags per judgment\")\n",
    "plt.savefig('results/'+filename+'/tags_per_judgment.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "for dur in stats['tags']:\n",
    "    print dur,float(sum(stats['tags'][dur]))/len(stats['tags'][dur])\n",
    "print 'avg:',float(sum([tag for tag in stats['tags'][dur] for dur in stats['tags']]))/len([tag for dur in stats['tags'] for tag in stats['tags'][dur]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Time before worker clicks button\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "sort(stats['time_before'])\n",
    "bp = ax.boxplot([stats['time_before'][dur] for dur in stats['time_before']])\n",
    "ax.set_xticklabels( ([dur for dur in stats['time_before']]) )\n",
    "plt.title(\"Time before worker clicks button\")\n",
    "plt.xlabel(\"Image duration (seconds)\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.savefig('results/'+filename+'/time_before.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "for dur in stats['time_before']:\n",
    "    print dur,float(sum(stats['time_before'][dur]))/len(stats['time_before'][dur])\n",
    "\n",
    "\n",
    "# Time the image was shown\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "sort(stats['time_during'])\n",
    "bp = ax.boxplot([stats['time_during'][dur] for dur in stats['time_during']])\n",
    "ax.set_xticklabels( ([dur for dur in stats['time_during']]) )\n",
    "plt.title(\"Time the image was shown\")\n",
    "plt.xlabel(\"Image duration (seconds)\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.savefig('results/'+filename+'/time_during.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "for dur in stats['time_during']:\n",
    "    print dur,float(sum(stats['time_during'][dur]))/len(stats['time_during'][dur])\n",
    "    \n",
    "    \n",
    "# Time after the image was hidden\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "sort(stats['time_after'])\n",
    "bp = ax.boxplot([stats['time_after'][dur] for dur in stats['time_after']])\n",
    "ax.set_xticklabels( ([dur for dur in stats['time_after']]) )\n",
    "plt.title(\"Time after the image was shown\")\n",
    "plt.xlabel(\"Image duration (seconds)\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.savefig('results/'+filename+'/time_after.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "for dur in stats['time_after']:\n",
    "    print dur,float(sum(stats['time_after'][dur]))/len(stats['time_after'][dur])\n",
    "    \n",
    "\n",
    "# Time the image was shown\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "sort(stats['time_total'])\n",
    "bp = ax.boxplot([stats['time_total'][dur] for dur in stats['time_total']])\n",
    "ax.set_xticklabels( ([dur for dur in stats['time_total']]) )\n",
    "plt.title(\"The total time of the task\")\n",
    "plt.xlabel(\"Image duration (seconds)\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.savefig('results/'+filename+'/time_total.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "for dur in stats['time_total']:\n",
    "    print dur,float(sum(stats['time_total'][dur]))/len(stats['time_total'][dur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get machine tags\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "    \n",
    "f = open('tag-cache.csv', 'r')\n",
    "reader = csv.DictReader(f)\n",
    "rows = {}\n",
    "for row in reader:\n",
    "    rows[row['id']] = {'url':row['url'],'imagga':row['imagga'],'clarifai':row['clarifai']}\n",
    "f.close()\n",
    "\n",
    "\n",
    "w = open('tag-cache.csv', 'wb')\n",
    "wr = csv.writer(w, delimiter=',')\n",
    "wr.writerow(['id','url','imagga','clarifai'])\n",
    "\n",
    "for image in images:\n",
    "    if image not in rows:\n",
    "        # Imagga tagging\n",
    "        url = \"http://api.imagga.com/v1/tagging\"\n",
    "        querystring = {\"url\":imageurls[image],\"version\":\"2\"}\n",
    "        headers = {\n",
    "            'accept': \"application/json\",\n",
    "            'authorization': \"Basic YWNjXzIxYzBlMzU4MjBlYWM3ZTo4NjhkODU2NzU4YTA0OTQyYTk4NWIzYWQ5NDNlOGNmYQ==\"\n",
    "        }\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        res = json.loads(response.text)\n",
    "\n",
    "        imagga = {}\n",
    "        for tag in res['results'][0]['tags']:\n",
    "            imagga[tag['tag']] = (tag['confidence']/100)\n",
    "        row['imagga'] = json.dumps(imagga)\n",
    "        \n",
    "        # Clarifai tagging\n",
    "        url = \"https://api.clarifai.com/v1/tag?url=\"+imageurls[image]+\"&access_token=6ZJdAQuAxNhKf08eiHuJicvRJ1MKNi\"\n",
    "        response = requests.request(\"GET\", url)\n",
    "        res = json.loads(response.text)\n",
    "        \n",
    "        clarifai = {}\n",
    "        for tag in range(len(res['results'][0]['result']['tag']['classes'])):\n",
    "            clarifai[res['results'][0]['result']['tag']['classes'][tag]] = res['results'][0]['result']['tag']['probs'][tag]\n",
    "        \n",
    "        wr.writerow([image,imageurls[image],json.dumps(imagga),json.dumps(clarifai)])\n",
    "        print 'new: ',image\n",
    "    else:\n",
    "        wr.writerow([image,rows[image]['url'],rows[image]['imagga'],rows[image]['clarifai']])\n",
    "        print 'existing: ',image\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique keywords:"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2a968605d5f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrowd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimagga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mclarifai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Unique keywords:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# plot crowd and machine tags\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "f = open('tag-cache.csv', 'r')\n",
    "reader = csv.DictReader(f)\n",
    "\n",
    "for row in reader:\n",
    "    image = row['id']\n",
    "    im = mpimg.imread(\"img/\"+image+\".jpg\")   \n",
    "    #figure(figsize = (10,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "    vector = {key:0 for dur in images[image] for key in images[image][dur]['tags'].keys()}\n",
    "    for dur in images[image]:\n",
    "        for tag in images[image][dur]['tags']:\n",
    "            vector[tag] += images[image][dur]['tags'][tag]\n",
    "    crowd = get_sentence_relation_score(vector)\n",
    "\n",
    "    imagga = json.loads(row['imagga'])\n",
    "    clarifai = json.loads(row['clarifai'])\n",
    "    keys = list(set(crowd.keys()+imagga.keys()+clarifai.keys())).sort()\n",
    "\n",
    "    print \"Unique keywords:\",len(keys)\n",
    " \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    yvals = []\n",
    "    zvals = []\n",
    "    kvals = []\n",
    "    labels = []\n",
    "    \n",
    "    for key in keys:\n",
    "        if key not in crowd:\n",
    "            yadd = 0\n",
    "        else:\n",
    "            yadd = crowd[key]\n",
    "\n",
    "        if key not in imagga:\n",
    "            zadd = 0\n",
    "        else:\n",
    "            zadd = imagga[key]\n",
    "    \n",
    "        if key not in clarifai:\n",
    "            kadd = 0\n",
    "        else:\n",
    "            kadd = clarifai[key]\n",
    "        \n",
    "        if yadd > 0.1 or zadd > 0.1 or kadd > 0.1:\n",
    "            yvals.append(yadd)\n",
    "            zvals.append(zadd)\n",
    "            kvals.append(kadd)\n",
    "            labels.append(key)\n",
    "            \n",
    "    N = len(yvals)\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.20       # the width of the bars\n",
    "\n",
    "    rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "    rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "    rects3 = ax.bar(ind+width*2, kvals, width, color='b')    \n",
    "    \n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_xticks(ind+width)\n",
    "    ax.set_xticklabels( (labels) )\n",
    "    ax.legend( (rects1[0], rects2[0], rects3[0]), ('crowd', 'imagga', 'clarifai') )\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            h = rect.get_height()\n",
    "            ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    #autolabel(rects1)\n",
    "    #autolabel(rects2)\n",
    "    #autolabel(rects3)\n",
    "    plt.setp(plt.xticks()[1], rotation=90)\n",
    "    plt.ylim(-0.01,1)\n",
    "    fig.set_size_inches(15,3)\n",
    "    plt.savefig('results/'+filename+'/machine_'+image+'.png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "\n",
    "\n",
    "fieldnames = ['type','1s','5s','15s','20s']\n",
    "\n",
    "w = open('results/pos-tag.csv', 'wb')\n",
    "wr = csv.writer(w, delimiter=',')\n",
    "wr.writerow(fieldnames)\n",
    "\n",
    "types = {}\n",
    "\n",
    "tagcount = {1:0,5:0,15:0,20:0}\n",
    "wordcount = {1:0,5:0,15:0,20:0}\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    for dur in images[image]:\n",
    "        for key in images[image][dur]['tags'].keys():\n",
    "            tagcount[dur] += images[image][dur]['tags'][key]\n",
    "\n",
    "            tokens=nltk.word_tokenize(key)\n",
    "            tagged=nltk.pos_tag(tokens)\n",
    "            simplifiedTags = [(word, nltk.map_tag('en-ptb', 'universal', tag)) for word, tag in tagged]\n",
    "\n",
    "            for tag in simplifiedTags:\n",
    "                wordcount[dur] += images[image][dur]['tags'][key]\n",
    "                t = tag[1]\n",
    "                if t not in types:\n",
    "                    types[t] = {1:0,5:0,15:0,20:0}\n",
    "                types[t][dur] += images[image][dur]['tags'][key]\n",
    "                #/ len(tokens)\n",
    "            \n",
    "    \n",
    "for t in types:\n",
    "    row = [t]\n",
    "    for d in [1,5,15,20]:\n",
    "        row.extend([types[t][d]])\n",
    "    \n",
    "    wr.writerow(row)\n",
    "    \n",
    "wr.writerow(['judgments']+[stats['judgments'][dur] for dur in [1,5,15,20]])\n",
    "wr.writerow(['tags']+[tagcount[dur] for dur in [1,5,15,20]])\n",
    "wr.writerow(['words']+[wordcount[dur] for dur in [1,5,15,20]])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<trial.n.02: PosScore=0.125 NegScore=0.0>\n",
      "<test.n.02: PosScore=0.125 NegScore=0.0>\n",
      "<examination.n.02: PosScore=0.0 NegScore=0.0>\n",
      "<test.n.04: PosScore=0.0 NegScore=0.0>\n",
      "<test.n.05: PosScore=0.0 NegScore=0.0>\n",
      "<test.n.06: PosScore=0.0 NegScore=0.0>\n",
      "<test.v.01: PosScore=0.375 NegScore=0.0>\n",
      "<screen.v.01: PosScore=0.375 NegScore=0.0>\n",
      "<quiz.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<test.v.04: PosScore=0.0 NegScore=0.0>\n",
      "<test.v.05: PosScore=0.0 NegScore=0.125>\n",
      "<test.v.06: PosScore=0.0 NegScore=0.0>\n",
      "<test.v.07: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "for syn in list(swn.senti_synsets('test')):\n",
    "    print syn"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
